{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyNN.nest as p\n",
    "import relu_utils as alg\n",
    "import spiking_relu as sr\n",
    "import random\n",
    "import mnist_utils as mu\n",
    "import os.path\n",
    "import sys\n",
    "import cnn_utils as cnnu\n",
    "import matplotlib.cm as cm\n",
    "#USAGE: spiking_dbn.py scaled_weight b10_epoc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_listf = 'scaled_weight'\n",
    "dbn_f = 'b10_epoc5'\n",
    "dbnet = alg.load_dict(dbn_f)\n",
    "cell_params_lif = {'cm': 0.25,\n",
    "                   'i_offset': 0.0,\n",
    "                   'tau_m': 20.0,\n",
    "                   'tau_refrac': 1.,\n",
    "                   'tau_syn_E': 1.0,\n",
    "                   'tau_syn_I': 1.0,\n",
    "                   'v_reset': -70.0,\n",
    "                   'v_rest': -65.0,\n",
    "                   'v_thresh': -50.0\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found w_list file\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('%s.pkl'%w_listf):\n",
    "    scaled_w = alg.load_dict(w_listf)\n",
    "    w = scaled_w['w']\n",
    "    k = scaled_w['k']\n",
    "    x0 = scaled_w['x0']\n",
    "    y0 = scaled_w['y0']\n",
    "    print 'found w_list file'\n",
    "else:\n",
    "    w, k, x0, y0 = sr.w_adjust(dbnet, cell_params_lif)\n",
    "    scaled_w = {}\n",
    "    scaled_w['w'] = w\n",
    "    scaled_w['k'] = k\n",
    "    scaled_w['x0'] = x0\n",
    "    scaled_w['y0'] = y0\n",
    "    alg.save_dict(scaled_w, w_listf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test = 10\n",
    "random.seed(0)\n",
    "dur_test = 1000\n",
    "silence = 200\n",
    "test_x = dbnet['test_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "test = test_x[offset:(offset+num_test), :]\n",
    "spike_source_data = sr.gen_spike_source(test)                \n",
    "spikes = sr.run_test(w, cell_params_lif, spike_source_data)\n",
    "spike_count = list()\n",
    "\n",
    "for i in range(w[-1].shape[1]):\n",
    "    index_i = np.where(spikes[:,0] == i)\n",
    "    spike_train = spikes[index_i, 1]\n",
    "    temp = sr.counter(spike_train, range(0, (dur_test+silence)*num_test,dur_test+silence), dur_test)\n",
    "    spike_count.append(temp)\n",
    "spike_count = np.array(spike_count)/(dur_test / 1000.)\n",
    "r = np.argmax(spike_count, axis=0)\n",
    "correct = np.sum(r == dbnet['test_y'][offset:offset+num_test]).astype(int) - len(np.where(spike_count.max(axis=0)==0)[0])\n",
    "print correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8498498498 8.71871871872 1.43143143143\n"
     ]
    }
   ],
   "source": [
    "rs = np.load('result_list.npy')\n",
    "limit = 9990.\n",
    "correct = np.where(rs[:limit,1] == 1)[0].shape[0]\n",
    "wrong = np.where(rs[:limit,1] == 0)[0].shape[0]\n",
    "noresp = np.where(rs[:limit,1] == -1)[0].shape[0]\n",
    "print  correct/limit*100.,  wrong/limit*100., noresp/limit*100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cnn_test(w_list, cell_para, spike_source_data):\n",
    "    pop_list = []\n",
    "    p.setup(timestep=1.0, min_delay=1.0, max_delay=3.0)\n",
    "    #input poisson layer\n",
    "    input_size = 28\n",
    "    pop_in = p.Population(input_size, p.SpikeSourceArray, {'spike_times' : []})\n",
    "    for j in range(input_size):\n",
    "        pop_in[j].spike_times = spike_source_data[j]\n",
    "    pop_list.append(pop_in)\n",
    "    \n",
    "    for w in w_list:        \n",
    "        pos_w = np.copy(w)\n",
    "        pos_w[pos_w < 0] = 0\n",
    "        neg_w = np.copy(w)\n",
    "        neg_w[neg_w > 0] = 0\n",
    "        \n",
    "        output_size = w.shape[1]\n",
    "        pop_out = p.Population(output_size, p.IF_curr_exp, cell_para)\n",
    "        p.Projection(pop_in, pop_out, p.AllToAllConnector(weights = pos_w), target='excitatory')\n",
    "        p.Projection(pop_in, pop_out, p.AllToAllConnector(weights = neg_w), target='inhibitory')\n",
    "        pop_list.append(pop_out)\n",
    "        pop_in = pop_out\n",
    "\n",
    "    pop_out.record()\n",
    "    run_time = np.ceil(np.max(spike_source_data)[0]/1000.)*1000\n",
    "    p.run(run_time)\n",
    "    spikes = pop_out.getSpikes(compatible_output=True)\n",
    "    p.end()\n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:  18.6158395604\n",
      "scale:  10.211737225\n",
      "scale:  7.27692308695\n",
      "scale:  14.3287809602\n",
      "46.3339326908\n",
      "scale:  2.70857821288\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "w_cnn, l_cnn = cnnu.readmat('cnn_relu.mat')#cnn609.mat softplus 3-5 train.\n",
    "#r = cnnu.test(w_cnn, l_cnn, test_x[:100,:], False)\n",
    "SUM_rate = 2000.\n",
    "tx = np.zeros((num_test, 784))\n",
    "for i in range(num_test):\n",
    "    tx[i] = test_x[i]/sum(test_x[i])*SUM_rate\n",
    "w_cnn, a = cnnu.scale_weight(w_cnn, l_cnn, tx[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_params_lif = {'cm': 0.25,\n",
    "                   'i_offset': 0.0,\n",
    "                   'tau_m': 20.0,\n",
    "                   'tau_refrac': 1.,\n",
    "                   'tau_syn_E': 1.0,\n",
    "                   'tau_syn_I': 1.0,\n",
    "                   'v_reset': -70.0,\n",
    "                   'v_rest': -65.0,\n",
    "                   'v_thresh': -50.0\n",
    "                   }\n",
    "def conv_conn(in_size, out_size, w):\n",
    "    conn_list_exci = []\n",
    "    conn_list_inhi = []\n",
    "    #conn_list = [] #nest works with mixed exci and inhi connections\n",
    "    k_size = in_size - out_size + 1\n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(k_size):\n",
    "                for ky in range(k_size):\n",
    "                    in_ind = (x_ind+kx) * in_size + (y_ind+ky)\n",
    "                    weight = w[k_size-1-ky][k_size-1-kx] #transpose(w)\n",
    "                    if weight>0:\n",
    "                        conn_list_exci.append((in_ind, out_ind, weight, 1.)) \n",
    "                    elif weight<0:\n",
    "                        conn_list_inhi.append((in_ind, out_ind, weight, 1.)) \n",
    "                    #conn_list.append((in_ind, out_ind, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "\n",
    "def pool_conn(in_size, out_size, w):\n",
    "    conn_list = []\n",
    "    step = in_size/out_size\n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(step):\n",
    "                for ky in range(step):\n",
    "                    in_ind = (x_ind*step+kx) * in_size + (y_ind*step+ky)\n",
    "                    conn_list.append((in_ind, out_ind, w, 1.))\n",
    "    return conn_list\n",
    "\n",
    "def out_conn(w):\n",
    "    conn_list_exci = []\n",
    "    conn_list_inhi = []\n",
    "    #conn_list = [] #nest works with mixed exci and inhi connections\n",
    "    for j in range(w.shape[0]):\n",
    "        for i in range(w.shape[1]):\n",
    "            weight = w[j][i]\n",
    "            if weight>0:\n",
    "                conn_list_exci.append((i, j, weight, 1.)) \n",
    "            elif weight<0:\n",
    "                conn_list_inhi.append((i, j, weight, 1.)) \n",
    "            #conn_list.append((i, j, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "    \n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(k_size):\n",
    "                for ky in range(k_size):\n",
    "                    in_ind = (x_ind+kx) * in_size + (y_ind+ky)\n",
    "                    weight = w[k_size-1-ky][k_size-1-kx] #transpose(w)\n",
    "                    if weight>0:\n",
    "                        conn_list_exci.append((in_ind, out_ind, weight, 1.)) \n",
    "                    elif weight<0:\n",
    "                        conn_list_inhi.append((in_ind, out_ind, weight, 1.)) \n",
    "                    #conn_list.append((in_ind, out_ind, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "\n",
    "def conv_pops(pop1, pop2, w):\n",
    "    in_size = int(np.sqrt(pop1.size))\n",
    "    out_size = int(np.sqrt(pop2.size))\n",
    "    conn_exci, conn_inhi = conv_conn(in_size, out_size, w)\n",
    "    if len(conn_exci)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "    if len(conn_inhi)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_inhi), target='inhibitory')\n",
    "    return\n",
    "\n",
    "def pool_pops(pop1, pop2, w):\n",
    "    in_size = int(np.sqrt(pop1.size))\n",
    "    out_size = int(np.sqrt(pop2.size))\n",
    "    conn_exci = pool_conn(in_size, out_size, w)\n",
    "    if len(conn_exci)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "    return\n",
    "\n",
    "def out_pops(pop_list, pop2, w_layer):\n",
    "    in_size = pop_list[0].size\n",
    "    out_size = pop2.size\n",
    "    for i in range(len(pop_list)):\n",
    "        w = w_layer[:,i*in_size:(i+1)*in_size]\n",
    "        conn_exci, conn_inhi = out_conn(w)\n",
    "        if len(conn_exci)>0:\n",
    "            p.Projection(pop_list[i], pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "        if len(conn_inhi)>0:\n",
    "            p.Projection(pop_list[i], pop2, p.FromListConnector(conn_inhi), target='inhibitory')\n",
    "    return\n",
    "\n",
    "def init_inputlayer(input_size, data):\n",
    "    pop_list = []\n",
    "    pop = p.Population(input_size*input_size, p.SpikeSourceArray, {'spike_times' : []})\n",
    "    spike_source_data = sr.gen_spike_source(data)\n",
    "    for j in range(input_size*input_size):\n",
    "        pop[j].spike_times = spike_source_data[j]\n",
    "    pop_list.append(pop)\n",
    "    return pop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_layer(pop_list_in, mode, k_size, w_layer):\n",
    "    in_num = len(pop_list_in) #populations number in previous layer\n",
    "    in_size = int(np.sqrt(pop_list_in[0].size)) #in_size*in_size = neuron_num per pop in the previous layer\n",
    "    pop_layer = []\n",
    "    if mode > 0: #convoluational layer\n",
    "        out_num = mode #populations number in current layer\n",
    "        print in_num, out_num\n",
    "        out_size = in_size - k_size + 1\n",
    "        for j in range(out_num):\n",
    "            pop_layer.append(p.Population(out_size*out_size, p.IF_curr_exp, cell_params_lif))\n",
    "            for i in range(in_num):\n",
    "                conv_pops(pop_list_in[i], pop_layer[j], w_layer[i][j])\n",
    "    elif mode == 0: #pooling layer\n",
    "        out_num = in_num #populations number in current layer\n",
    "        print in_num, out_num\n",
    "        out_size = in_size/k_size\n",
    "        for j in range(out_num):\n",
    "            pop_layer.append(p.Population(out_size*out_size, p.IF_curr_exp, cell_params_lif))\n",
    "            pool_pops(pop_list_in[j], pop_layer[j], w_layer[0][0])\n",
    "    elif mode == -1: #top layer\n",
    "        out_size = k_size\n",
    "        print out_size\n",
    "        pop_layer.append(p.Population(out_size, p.IF_curr_exp, cell_params_lif))\n",
    "        out_pops(pop_list_in, pop_layer[0], w_layer)\n",
    "    return pop_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "tmp_x = sio.loadmat('mnist.mat')['test_x']\n",
    "tmp_x = np.transpose(tmp_x, (2, 0, 1))\n",
    "tmp_x = np.reshape(tmp_x, (tmp_x.shape[0], 28*28), order='F' )\n",
    "\n",
    "tmp_y = sio.loadmat('mnist.mat')['test_y']\n",
    "tmp_y = np.argmax(tmp_y, axis=0)\n",
    "num_test = 100\n",
    "offset = 0\n",
    "test = tmp_x[offset:(offset+num_test), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6\n",
      "6 6\n",
      "6 12\n",
      "12 12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "p.setup(timestep=1.0, min_delay=1.0, max_delay=3.0)\n",
    "L = l_cnn\n",
    "input_size = L[0][1]\n",
    "pops_list = []\n",
    "pops_list.append(init_inputlayer(input_size, test))\n",
    "\n",
    "for l in range(5):\n",
    "    pops_list.append(construct_layer(pops_list[l], L[l+1][0], L[l+1][1], w_cnn[l]))\n",
    "pops_list[5][0].record()\n",
    "p.run((dur_test+silence)*num_test)\n",
    "spikes = pops_list[5][0].getSpikes(compatible_output=True)\n",
    "p.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "spike_count = []\n",
    "for i in range(10):\n",
    "    index_i = np.where(spikes[:,0] == i)\n",
    "    spike_train = spikes[index_i, 1]\n",
    "    temp = sr.counter(spike_train, range(0, (dur_test+silence)*num_test,dur_test+silence), dur_test)\n",
    "    spike_count.append(temp)\n",
    "spike_count = np.array(spike_count)/(dur_test / 1000.)\n",
    "r = np.argmax(spike_count, axis=0)\n",
    "correct = np.sum(r == tmp_y[offset:(offset+num_test)]).astype(int) #- len(np.where(spike_count.max(axis=0)==0)[0])\n",
    "print correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr.plot_spikes(spikes,'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
