{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyNN.nest as p\n",
    "import relu_utils as alg\n",
    "import spiking_relu as sr\n",
    "import random\n",
    "import mnist_utils as mu\n",
    "import os.path\n",
    "import sys\n",
    "import cnn_utils as cnnu\n",
    "import matplotlib.cm as cm\n",
    "#USAGE: spiking_dbn.py scaled_weight b10_epoc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_listf = 'scaled_weight'\n",
    "dbn_f = 'b10_epoc5'\n",
    "dbnet = alg.load_dict(dbn_f)\n",
    "cell_params_lif = {'cm': 0.25,\n",
    "                   'i_offset': 0.0,\n",
    "                   'tau_m': 20.0,\n",
    "                   'tau_refrac': 1.,\n",
    "                   'tau_syn_E': 1.0,\n",
    "                   'tau_syn_I': 1.0,\n",
    "                   'v_reset': -70.0,\n",
    "                   'v_rest': -65.0,\n",
    "                   'v_thresh': -50.0\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found w_list file\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('%s.pkl'%w_listf):\n",
    "    scaled_w = alg.load_dict(w_listf)\n",
    "    w = scaled_w['w']\n",
    "    k = scaled_w['k']\n",
    "    x0 = scaled_w['x0']\n",
    "    y0 = scaled_w['y0']\n",
    "    print 'found w_list file'\n",
    "else:\n",
    "    w, k, x0, y0 = sr.w_adjust(dbnet, cell_params_lif)\n",
    "    scaled_w = {}\n",
    "    scaled_w['w'] = w\n",
    "    scaled_w['k'] = k\n",
    "    scaled_w['x0'] = x0\n",
    "    scaled_w['y0'] = y0\n",
    "    alg.save_dict(scaled_w, w_listf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test = 10\n",
    "random.seed(0)\n",
    "dur_test = 1000\n",
    "silence = 200\n",
    "test_x = dbnet['test_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "test = test_x[offset:(offset+num_test), :]\n",
    "spike_source_data = sr.gen_spike_source(test)                \n",
    "spikes = sr.run_test(w, cell_params_lif, spike_source_data)\n",
    "spike_count = list()\n",
    "\n",
    "for i in range(w[-1].shape[1]):\n",
    "    index_i = np.where(spikes[:,0] == i)\n",
    "    spike_train = spikes[index_i, 1]\n",
    "    temp = sr.counter(spike_train, range(0, (dur_test+silence)*num_test,dur_test+silence), dur_test)\n",
    "    spike_count.append(temp)\n",
    "spike_count = np.array(spike_count)/(dur_test / 1000.)\n",
    "r = np.argmax(spike_count, axis=0)\n",
    "correct = np.sum(r == dbnet['test_y'][offset:offset+num_test]).astype(int) - len(np.where(spike_count.max(axis=0)==0)[0])\n",
    "print correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8498498498 8.71871871872 1.43143143143\n"
     ]
    }
   ],
   "source": [
    "rs = np.load('result_list.npy')\n",
    "limit = 9990.\n",
    "correct = np.where(rs[:limit,1] == 1)[0].shape[0]\n",
    "wrong = np.where(rs[:limit,1] == 0)[0].shape[0]\n",
    "noresp = np.where(rs[:limit,1] == -1)[0].shape[0]\n",
    "print  correct/limit*100.,  wrong/limit*100., noresp/limit*100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "tmp_x = sio.loadmat('mnist.mat')['test_x']\n",
    "tmp_x = np.transpose(tmp_x, (2, 0, 1))\n",
    "tmp_x = np.reshape(tmp_x, (tmp_x.shape[0], 28*28), order='F' )\n",
    "\n",
    "tmp_y = sio.loadmat('mnist.mat')['test_y']\n",
    "tmp_y = np.argmax(tmp_y, axis=0)\n",
    "offset = 0\n",
    "dur_test = 10000\n",
    "silence = 200\n",
    "num_test = 100\n",
    "test = tmp_x[offset:(offset+num_test), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_cnn, l_cnn = cnnu.readmat('cnn_relu.mat')#cnn609.mat softplus 3-5 train.\n",
    "#r = cnnu.test(w_cnn, l_cnn, test_x[:100,:], False)\n",
    "SUM_rate = 2000.\n",
    "tx = np.zeros((num_test, 784))\n",
    "for i in range(num_test):\n",
    "    tx[i] = test[i]/sum(test[i])*SUM_rate\n",
    "#w_cnn, a = cnnu.scale_weight(w_cnn, l_cnn, tx[:num_test,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_params_lif = {'cm': 0.25,\n",
    "                   'i_offset': 0.0,\n",
    "                   'tau_m': 20.0,\n",
    "                   'tau_refrac': 1.,\n",
    "                   'tau_syn_E': 10.0,\n",
    "                   'tau_syn_I': 10.0,\n",
    "                   'v_reset': -70.0,\n",
    "                   'v_rest': -65.0,\n",
    "                   'v_thresh': -50.0\n",
    "                   }\n",
    "def conv_conn(in_size, out_size, w):\n",
    "    conn_list_exci = []\n",
    "    conn_list_inhi = []\n",
    "    #conn_list = [] #nest works with mixed exci and inhi connections\n",
    "    k_size = in_size - out_size + 1\n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(k_size):\n",
    "                for ky in range(k_size):\n",
    "                    in_ind = (x_ind+kx) * in_size + (y_ind+ky)\n",
    "                    weight = w[k_size-1-ky][k_size-1-kx] #transpose(w)\n",
    "                    if weight>0:\n",
    "                        conn_list_exci.append((in_ind, out_ind, weight, 1.)) \n",
    "                    elif weight<0:\n",
    "                        conn_list_inhi.append((in_ind, out_ind, weight, 1.)) \n",
    "                    #conn_list.append((in_ind, out_ind, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "\n",
    "def pool_conn(in_size, out_size, w):\n",
    "    conn_list = []\n",
    "    step = in_size/out_size\n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(step):\n",
    "                for ky in range(step):\n",
    "                    in_ind = (x_ind*step+kx) * in_size + (y_ind*step+ky)\n",
    "                    conn_list.append((in_ind, out_ind, w, 1.))\n",
    "    return conn_list\n",
    "\n",
    "def out_conn(w):\n",
    "    conn_list_exci = []\n",
    "    conn_list_inhi = []\n",
    "    #conn_list = [] #nest works with mixed exci and inhi connections\n",
    "    for j in range(w.shape[0]):\n",
    "        for i in range(w.shape[1]):\n",
    "            weight = w[j][i]\n",
    "            if weight>0:\n",
    "                conn_list_exci.append((i, j, weight, 1.)) \n",
    "            elif weight<0:\n",
    "                conn_list_inhi.append((i, j, weight, 1.)) \n",
    "            #conn_list.append((i, j, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "    \n",
    "    for x_ind in range(out_size):\n",
    "        for y_ind in range(out_size):\n",
    "            out_ind = x_ind * out_size + y_ind\n",
    "            for kx in range(k_size):\n",
    "                for ky in range(k_size):\n",
    "                    in_ind = (x_ind+kx) * in_size + (y_ind+ky)\n",
    "                    weight = w[k_size-1-ky][k_size-1-kx] #transpose(w)\n",
    "                    if weight>0:\n",
    "                        conn_list_exci.append((in_ind, out_ind, weight, 1.)) \n",
    "                    elif weight<0:\n",
    "                        conn_list_inhi.append((in_ind, out_ind, weight, 1.)) \n",
    "                    #conn_list.append((in_ind, out_ind, weight, 1.))\n",
    "    return conn_list_exci, conn_list_inhi#, conn_list\n",
    "\n",
    "def conv_pops(pop1, pop2, w):\n",
    "    in_size = int(np.sqrt(pop1.size))\n",
    "    out_size = int(np.sqrt(pop2.size))\n",
    "    conn_exci, conn_inhi = conv_conn(in_size, out_size, w)\n",
    "    if len(conn_exci)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "    if len(conn_inhi)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_inhi), target='inhibitory')\n",
    "    return\n",
    "\n",
    "def pool_pops(pop1, pop2, w):\n",
    "    in_size = int(np.sqrt(pop1.size))\n",
    "    out_size = int(np.sqrt(pop2.size))\n",
    "    conn_exci = pool_conn(in_size, out_size, w)\n",
    "    if len(conn_exci)>0:\n",
    "        p.Projection(pop1, pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "    return\n",
    "\n",
    "def out_pops(pop_list, pop2, w_layer):\n",
    "    in_size = pop_list[0].size\n",
    "    out_size = pop2.size\n",
    "    for i in range(len(pop_list)):\n",
    "        w = w_layer[:,i*in_size:(i+1)*in_size]\n",
    "        conn_exci, conn_inhi = out_conn(w)\n",
    "        if len(conn_exci)>0:\n",
    "            p.Projection(pop_list[i], pop2, p.FromListConnector(conn_exci), target='excitatory')\n",
    "        if len(conn_inhi)>0:\n",
    "            p.Projection(pop_list[i], pop2, p.FromListConnector(conn_inhi), target='inhibitory')\n",
    "    return\n",
    "\n",
    "def init_inputlayer(input_size, data):\n",
    "    pop_list = []\n",
    "    pop = p.Population(input_size*input_size, p.SpikeSourceArray, {'spike_times' : []})\n",
    "    spike_source_data = sr.gen_spike_source(data,dur_test = 10000)\n",
    "    for j in range(input_size*input_size):\n",
    "        pop[j].spike_times = spike_source_data[j]\n",
    "    pop_list.append(pop)\n",
    "    return pop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_layer(pop_list_in, mode, k_size, w_layer):\n",
    "    in_num = len(pop_list_in) #populations number in previous layer\n",
    "    in_size = int(np.sqrt(pop_list_in[0].size)) #in_size*in_size = neuron_num per pop in the previous layer\n",
    "    pop_layer = []\n",
    "    if mode > 0: #convoluational layer\n",
    "        out_num = mode #populations number in current layer\n",
    "        print in_num, out_num\n",
    "        out_size = in_size - k_size + 1\n",
    "        for j in range(out_num):\n",
    "            pop_layer.append(p.Population(out_size*out_size, p.IF_curr_exp, cell_params_lif))\n",
    "            for i in range(in_num):\n",
    "                conv_pops(pop_list_in[i], pop_layer[j], w_layer[i][j])\n",
    "    elif mode == 0: #pooling layer\n",
    "        out_num = in_num #populations number in current layer\n",
    "        print in_num, out_num\n",
    "        out_size = in_size/k_size\n",
    "        for j in range(out_num):\n",
    "            pop_layer.append(p.Population(out_size*out_size, p.IF_curr_exp, cell_params_lif))\n",
    "            pool_pops(pop_list_in[j], pop_layer[j], w_layer[0][0])\n",
    "    elif mode == -1: #top layer\n",
    "        out_size = k_size\n",
    "        print out_size\n",
    "        pop_layer.append(p.Population(out_size, p.IF_curr_exp, cell_params_lif))\n",
    "        out_pops(pop_list_in, pop_layer[0], w_layer)\n",
    "    return pop_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6\n",
      "6 6\n",
      "6 12\n",
      "12 12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "p.setup(timestep=1.0, min_delay=1.0, max_delay=3.0)\n",
    "L = l_cnn\n",
    "num_test = 100\n",
    "random.seed(0)\n",
    "input_size = L[0][1]\n",
    "pops_list = []\n",
    "pops_list.append(init_inputlayer(input_size, test[:num_test, :]))\n",
    "\n",
    "for l in range(5):\n",
    "    pops_list.append(construct_layer(pops_list[l], L[l+1][0], L[l+1][1], w_cnn[l]))\n",
    "observe = pops_list[5][0]\n",
    "inpop = pops_list[0][0]\n",
    "observe.record()\n",
    "inpop.record()\n",
    "p.run((dur_test+silence)*num_test)\n",
    "spikes = observe.getSpikes(compatible_output=True)\n",
    "spikein = inpop.getSpikes(compatible_output=True)\n",
    "p.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_digit(img_raw, size=28, crange=(0.0, 40.)):\n",
    "    #img_raw = np.uint8(img_raw)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    im = plt.imshow(np.reshape(img_raw,(size,size)), cmap=cm.gray_r,interpolation='none', clim=crange)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.show()\n",
    "def count_spikes(spikes, num_neuron):\n",
    "    spike_count = []\n",
    "    for i in range(num_neuron):\n",
    "        index_i = np.where(spikes[:,0] == i)\n",
    "        spike_train = spikes[index_i, 1]\n",
    "        temp = sr.counter(spike_train, range(0, (dur_test+silence)*num_test,dur_test+silence), dur_test)\n",
    "        spike_count.append(temp)\n",
    "    spike_count = np.array(spike_count)/(dur_test / 1000.)\n",
    "    spike_count = np.array(spike_count)\n",
    "    return spike_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "spike_count = []\n",
    "for i in range(10):\n",
    "    index_i = np.where(spikes[:,0] == i)\n",
    "    spike_train = spikes[index_i, 1]\n",
    "    temp = sr.counter(spike_train, range(0, (dur_test+silence)*num_test,dur_test+silence), dur_test)\n",
    "    spike_count.append(temp)\n",
    "spike_count = np.array(spike_count)/(dur_test / 1000.)\n",
    "r = np.argmax(spike_count, axis=0)\n",
    "correct = np.sum(r == tmp_y[offset:(offset+num_test)]).astype(int) #- len(np.where(spike_count.max(axis=0)==0)[0])\n",
    "print correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  42.2,  193.7,   37.3,   19.5,   54.6,   89.9,   53.3,   67.4,\n",
       "        113.7,   26. ,   68.6,   89.9,   89.1,  109.7,  151.4,   91.9,\n",
       "        127. ,   72.4,   47.1,   92.8,   33.3,   66.4,  134.8,   35.3,\n",
       "        134.9,   13.6,   18.7,  102.4,   45.9,   26.7,  110.9,   81. ,\n",
       "        114.1,   14.8,   42.3,   41.8,  111.5,  102.4,   98.3,   50.3,\n",
       "        120. ,   27.6,   50.2,   10. ,   84.3,   43.5,   77.8,   67.6,\n",
       "         38.4,  227. ,   75.2,   56.9,   81.1,   52.8,   73.2,  133.5,\n",
       "         58.5,   48.6,  118.1,  150.5,  103.3,   71. ,  229.3,   61.6,\n",
       "         86.2,   31.3,  181.8,  117.6,   35.3,   79.1,   42.9,  153.3,\n",
       "        123.8,   46.6,   71.3,   74.3,  108.5,   69.3,  193.7,   22.4,\n",
       "        101.1,   51.6,   72.3,   85.5,   67.9,   23.9,   45.4,    6.5,\n",
       "        130.3,  147.8,   99.3,  102. ,   64. ,   28. ,   66.5,   82. ,\n",
       "         87.1,  117. ,   57.1,   99.6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(spike_count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
